apiVersion: v1
kind: ConfigMap
metadata:
  name: vllm-config
  namespace: default
  labels:
    app: my-inference
data:
  # CLI-Argumente f√ºr den vLLM OpenAI API Server
  vllm-args: "--model /cache/models/microsoft_Phi-3-mini-4k-instruct --tensor-parallel-size 2 --trust-remote-code --port 8000 --gpu-memory-utilization 0.85"
